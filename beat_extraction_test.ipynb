{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4970ee-349e-460e-ac7a-0ac2b49e3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from util.ioUtil import *\n",
    "import librosa.display\n",
    "from matplotlib import pyplot as plt\n",
    "import soundfile as sf\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e5259-9b12-4a10-98c5-1c38c4a6a143",
   "metadata": {},
   "source": [
    "# Test of using beat extraction from librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964ea18d-2ead-4c35-b25f-5b04286f69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"F:/MASC/video_timing_interaction/songs/\"\n",
    "file_name = \"whithers_face.mp4\"\n",
    "drum_sample_path = \"F:/MASC/video_timing_interaction/drum_samples/\"\n",
    "drum_file_name = \"highHatclosed0.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cd1635-1530-4007-87b4-3b9ef4445ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_audio_from_video(file_name, test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cea3194-e900-4fd9-ad96-2c2b121c22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = librosa.load(test_file_path+file_name[:-3]+\"mp3\", sr=44100)\n",
    "sr = file[1]\n",
    "y = file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "662c6bac-a070-4b38-a714-f75d9a24006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_hat = librosa.load(drum_sample_path+drum_file_name, sr=44100)[0]\n",
    "drum_track = np.zeros(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70043ef7-0454-42b3-b7bd-651b9d7c9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beats = librosa.beat.beat_track(y=y, sr=sr, tightness=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0eb6e704-fd85-4c8e-9fba-6655adecec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = librosa.frames_to_time(beats, sr=sr)\n",
    "for i in range(0, len(t)):\n",
    "    onset_time = int(t[i] * 44100)\n",
    "    drum_track[onset_time:onset_time+high_hat.shape[0]] = high_hat\n",
    "sf.write(test_file_path + 'drum_rhythm.wav', drum_track, 44100, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05650e2c-9ec6-4210-8a64-2f666552fc6c",
   "metadata": {},
   "source": [
    "# Just using onset detection on singing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0c4a9c-90dc-4a42-b455-62eb30337ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"F:/MASC/video_timing_interaction/songs/\"\n",
    "file_name = \"piah.wav\"\n",
    "video_file_name = \"piah.mp4\"\n",
    "drum_sample_path = \"F:/MASC/video_timing_interaction/drum_samples/\"\n",
    "drum_file_name = \"highHatclosed0.mp3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dcf40b3-3d08-4a8a-a37d-7728c90c8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(test_file_path+file_name, sr=16000)\n",
    "beat_only = librosa.feature.melspectrogram(y, sr=sr)\n",
    "beat_only = librosa.stft(y, hop_length=256, n_fft=1024)\n",
    "\n",
    "high_hat = librosa.load(drum_sample_path+drum_file_name, sr=16000)[0]\n",
    "drum_track = np.zeros(y.shape)\n",
    "\n",
    "ts = (512.0/sr) * np.arange(1, beat_only.shape[1]+1) + 512.0/sr/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7252c0bf-959f-4196-a66c-082352814d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_default = librosa.onset.onset_detect(y=y, sr=sr, hop_length=256,\n",
    "                                           units='frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd81564-9869-47cc-a2ce-c3052ab0d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = onset_default\n",
    "for i in range(0, len(t)-1):\n",
    "    onset_time = int(t[i] * 256)\n",
    "    drum_track[onset_time:onset_time+high_hat.shape[0]] = high_hat\n",
    "sf.write(test_file_path + 'onset_only_drum_rhythm.wav', drum_track, sr, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ef8423-d87c-4404-8ebc-e4edde975914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frames grabbed!\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(cv.samples.findFile(test_file_path+video_file_name))\n",
    "ret, frame1 = cap.read()\n",
    "prvs_img = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "counter = 0\n",
    "flow_out = [] \n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "    next_img = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs_img, next_img, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    flow_out.append(flow)\n",
    "    prvs_img = next_img\n",
    "    counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10a9c144-f9e2-4492-9c4d-e491919b2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "flow_t = flow_out[t]\n",
    "vert_up_dir = np.ones(flow_t.shape)\n",
    "vert_up_dir[:, :, 1] = vert_up_dir[:, :, 1] * 0\n",
    "# compute angle of the vector by first computing\n",
    "# dot product between flow direction and vertical\n",
    "# up, then dividing by magnitude of flow_t\n",
    "dot_product = (vert_up_dir * flow_t).sum(axis=2) \n",
    "magnitude = np.sqrt((flow_t * flow_t).sum(axis=2))\n",
    "magnitude = np.where(magnitude==0, 1, magnitude)\n",
    "dire = dot_product / magnitude + np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d217441-5afb-407c-8098-a8bfa257a92f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39419479077826436\n"
     ]
    }
   ],
   "source": [
    "print(dire.min())\n",
    "bin_a = np.floor(a/np.pi * N_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6f7b287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.345354010102106"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.39*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d63d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visemenet",
   "language": "python",
   "name": "visemenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
